{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "kjU0M_EshR08",
    "outputId": "6df43740-18af-4c61-ae55-18ef59eeb3f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Sep 15 22:54:12 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 430.40       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   43C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5_qNrOHZigM5",
    "outputId": "18ff703f-b706-4dcd-9ab6-8d369c28a4af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.204.53.0"
     ]
    }
   ],
   "source": [
    "!curl ipecho.net/plain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "kRHkluqKIEQ6",
    "outputId": "2b53721f-4651-4066-f64a-08914c45b57a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fWezShG4jNqd"
   },
   "outputs": [],
   "source": [
    "download_dataset =True\n",
    "if download_dataset:\n",
    "  !pip install kaggle --upgrade\n",
    "  try:\n",
    "    # You can access google drive documents at '/content/gdrive/My Drive'\n",
    "    from google.colab import drive\n",
    "    drive.mount('./gdrive')\n",
    "\n",
    "    # Copy ssh key\n",
    "    !mkdir -p ~/.kaggle\n",
    "    !cp '/content/gdrive/My Drive/Colab Notebooks/kaggle.json' ~/.kaggle\n",
    "\n",
    "  except ImportError:\n",
    "      print(\"Google drive not available. You should add your kaggle key to ~/.kaggle\")\n",
    "\n",
    "  !mkdir -p kaggle/\n",
    "  !cd kaggle; kaggle datasets download -d hellababorsa/pretain-aptos-253-190915;kaggle datasets download -d hellababorsa/mvcv42fivefold;kaggle competitions download -c aptos2019-blindness-detection\n",
    "  !cd kaggle; unzip /content/kaggle/mvcv42fivefold.zip -d mycv42; unzip /content/kaggle/pretain-aptos-253-190915.zip -d pretain190915; unzip /content/kaggle/train_images.zip -d traindataset19\n",
    "  data_directory = \"kaggle/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6dMl6CWbhR1C"
   },
   "source": [
    "#### plan v174 efficientnetb5, lr2e-4, ep4, freeze all-1 till ep0, weights, optimized kappa, no weights, seed42, crop reflect circle, output layer with avg and maxpool and dropout0.3, RAdam wd 0.005 step 10 0.9, train2015valid2019 then finetune valid part of 2019 within same, autoaugment and cutout and rotate, mse+bce, 9th preprocess + 4th augment no randomcrop no clahe and replace dihedral with flipxx and add 1st solution parameter in jitter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "iH67sqq6hR1E",
    "outputId": "f83d77b1-93fb-48e8-f367-c43e07228b81"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bsz=32\n",
    "weight0 = 0.25#0.125#0.0276*4\n",
    "weight1 = 0.25#0.5#0.0596*4\n",
    "weight2 = 0.25#0.25#0.076*4\n",
    "weight3 = 0.25#1.#0.0925*4\n",
    "weight4 = 0.25#1.#0.1541*4\n",
    "auxloss = 0.5\n",
    "weight_decay = 0.005\n",
    "num_epochs = 15#13#1#6\n",
    "lr = 2e-4\n",
    "n_freeze = 0\n",
    "picSize=260+20\n",
    "warmup = int(4*90000*0.05/32)\n",
    "model_name = 'efficientnet-b2'\n",
    "saved_pretrain_model = 'kaggle/pretain190915/model_ep4.bin'\n",
    "output_unit = 1408 #2560#2048#int(3072/2)#1408\n",
    "aux_loss = 0.5\n",
    "loss_weights = (25810+2443+5292+873+708+39533+3762+7861+1214+1206)/(25810*weight0+2443*weight1+5292*weight2+873*weight3+708*weight4+39533*weight0+3762*weight1+7861*weight2+1214*weight3+1206*weight4)\n",
    "#(57822*0.25+5662*0.25+12187*0.25+1964*0.25+1903*0.25)/(57822+5662+12187+1964+1903)\n",
    "see_train = False\n",
    "see_valid = False\n",
    "train_before = True\n",
    "loss_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "3Yvdq-qfhR1I",
    "outputId": "d81b2787-c927-4a2b-8acd-a9aa94a5f9a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-09-15 22:58:47--  https://raw.githubusercontent.com/4uiiurz1/pytorch-auto-augment/master/auto_augment.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9703 (9.5K) [text/plain]\n",
      "Saving to: ‘auto_augment.py’\n",
      "\n",
      "\r",
      "auto_augment.py       0%[                    ]       0  --.-KB/s               \r",
      "auto_augment.py     100%[===================>]   9.48K  --.-KB/s    in 0s      \n",
      "\n",
      "2019-09-15 22:58:47 (167 MB/s) - ‘auto_augment.py’ saved [9703/9703]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/4uiiurz1/pytorch-auto-augment/master/auto_augment.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "E-M96aI4hR1L",
    "outputId": "c9639d5a-379f-417b-c841-8e7877cb70d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting efficientnet-pytorch\n",
      "  Downloading https://files.pythonhosted.org/packages/12/f8/35453605c6c471fc406a137a894fb381b05ae9f174b2ca4956592512374e/efficientnet_pytorch-0.4.0.tar.gz\n",
      "Requirement already satisfied, skipping upgrade: torch in /usr/local/lib/python3.6/dist-packages (from efficientnet-pytorch) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet-pytorch) (1.16.5)\n",
      "Building wheels for collected packages: efficientnet-pytorch\n",
      "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.4.0-cp36-none-any.whl size=11149 sha256=24598614d6dad5c54db26c58a5072c55c86b934ebcd51f55100e1b1a6cdd4a08\n",
      "  Stored in directory: /root/.cache/pip/wheels/27/56/13/5bdaa98ca8bd7d5da65cc741987dd14391b87fa1a09081d17a\n",
      "Successfully built efficientnet-pytorch\n",
      "Installing collected packages: efficientnet-pytorch\n",
      "Successfully installed efficientnet-pytorch-0.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade efficientnet-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_kg_hide-output": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "TTfakSxohR1O",
    "outputId": "e30e6bc0-3f4e-41af-c84c-1d82e8b68944"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'apex'...\n",
      "remote: Enumerating objects: 11, done.\u001b[K\n",
      "remote: Counting objects:   9% (1/11)\u001b[K\r",
      "remote: Counting objects:  18% (2/11)\u001b[K\r",
      "remote: Counting objects:  27% (3/11)\u001b[K\r",
      "remote: Counting objects:  36% (4/11)\u001b[K\r",
      "remote: Counting objects:  45% (5/11)\u001b[K\r",
      "remote: Counting objects:  54% (6/11)\u001b[K\r",
      "remote: Counting objects:  63% (7/11)\u001b[K\r",
      "remote: Counting objects:  72% (8/11)\u001b[K\r",
      "remote: Counting objects:  81% (9/11)\u001b[K\r",
      "remote: Counting objects:  90% (10/11)\u001b[K\r",
      "remote: Counting objects: 100% (11/11)\u001b[K\r",
      "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
      "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
      "remote: Total 5433 (delta 1), reused 3 (delta 1), pack-reused 5422\u001b[K\n",
      "Receiving objects: 100% (5433/5433), 13.33 MiB | 5.28 MiB/s, done.\n",
      "Resolving deltas: 100% (3512/3512), done.\n",
      "/usr/local/lib/python3.6/dist-packages/pip/_internal/commands/install.py:243: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\n",
      "  cmdoptions.check_install_build_global(options)\n",
      "Created temporary directory: /tmp/pip-ephem-wheel-cache-r15re3bp\n",
      "Created temporary directory: /tmp/pip-req-tracker-pjs4rw11\n",
      "Created requirements tracker '/tmp/pip-req-tracker-pjs4rw11'\n",
      "Created temporary directory: /tmp/pip-install-sdrtvp5n\n",
      "Processing ./apex\n",
      "  Created temporary directory: /tmp/pip-req-build-c9h2m6um\n",
      "  Added file:///content/apex to build tracker '/tmp/pip-req-tracker-pjs4rw11'\n",
      "    Running setup.py (path:/tmp/pip-req-build-c9h2m6um/setup.py) egg_info for package from file:///content/apex\n",
      "    Running command python setup.py egg_info\n",
      "    torch.__version__  =  1.1.0\n",
      "    running egg_info\n",
      "    creating pip-egg-info/apex.egg-info\n",
      "    writing pip-egg-info/apex.egg-info/PKG-INFO\n",
      "    writing dependency_links to pip-egg-info/apex.egg-info/dependency_links.txt\n",
      "    writing top-level names to pip-egg-info/apex.egg-info/top_level.txt\n",
      "    writing manifest file 'pip-egg-info/apex.egg-info/SOURCES.txt'\n",
      "    writing manifest file 'pip-egg-info/apex.egg-info/SOURCES.txt'\n",
      "    /tmp/pip-req-build-c9h2m6um/setup.py:43: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
      "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
      "  Source in /tmp/pip-req-build-c9h2m6um has version 0.1, which satisfies requirement apex==0.1 from file:///content/apex\n",
      "  Removed apex==0.1 from file:///content/apex from build tracker '/tmp/pip-req-tracker-pjs4rw11'\n",
      "Skipping bdist_wheel for apex, due to binaries being disabled for it.\n",
      "Installing collected packages: apex\n",
      "  Created temporary directory: /tmp/pip-record-293ocy02\n",
      "    Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-c9h2m6um/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-c9h2m6um/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-293ocy02/install-record.txt --single-version-externally-managed --compile\n",
      "    torch.__version__  =  1.1.0\n",
      "    /tmp/pip-req-build-c9h2m6um/setup.py:43: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
      "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
      "\n",
      "    Compiling cuda extensions with\n",
      "    nvcc: NVIDIA (R) Cuda compiler driver\n",
      "    Copyright (c) 2005-2018 NVIDIA Corporation\n",
      "    Built on Sat_Aug_25_21:08:01_CDT_2018\n",
      "    Cuda compilation tools, release 10.0, V10.0.130\n",
      "    from /usr/local/cuda/bin\n",
      "\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build/lib.linux-x86_64-3.6\n",
      "    creating build/lib.linux-x86_64-3.6/apex\n",
      "    copying apex/__init__.py -> build/lib.linux-x86_64-3.6/apex\n",
      "    creating build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "    copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "    copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "    copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "    copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "    creating build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/__init__.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/LARC.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/distributed.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    creating build/lib.linux-x86_64-3.6/apex/pyprof\n",
      "    copying apex/pyprof/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof\n",
      "    creating build/lib.linux-x86_64-3.6/apex/normalization\n",
      "    copying apex/normalization/__init__.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
      "    copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
      "    creating build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/wrap.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/utils.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/scaler.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/amp.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/handle.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/frontend.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/__version__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/opt.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/_initialize.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    creating build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "    copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "    copying apex/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "    copying apex/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "    copying apex/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "    copying apex/optimizers/fused_novograd.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "    copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "    creating build/lib.linux-x86_64-3.6/apex/contrib\n",
      "    copying apex/contrib/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib\n",
      "    creating build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
      "    copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
      "    copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
      "    creating build/lib.linux-x86_64-3.6/apex/RNN\n",
      "    copying apex/RNN/__init__.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
      "    copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
      "    copying apex/RNN/models.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
      "    copying apex/RNN/cells.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
      "    creating build/lib.linux-x86_64-3.6/apex/reparameterization\n",
      "    copying apex/reparameterization/__init__.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
      "    copying apex/reparameterization/reparameterization.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
      "    copying apex/reparameterization/weight_norm.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
      "    creating build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/pooling.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/randomSample.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/optim.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/__main__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/conv.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/misc.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/linear.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/blas.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/utility.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/activation.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/data.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/pointwise.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/recurrentCell.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/reduction.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/embedding.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/softmax.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/loss.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/base.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/convert.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/prof.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/normalization.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/usage.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/output.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/dropout.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
      "    creating build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
      "    copying apex/pyprof/nvtx/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
      "    copying apex/pyprof/nvtx/nvmarker.py -> build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
      "    creating build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
      "    copying apex/pyprof/parse/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
      "    copying apex/pyprof/parse/__main__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
      "    copying apex/pyprof/parse/nvvp.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
      "    copying apex/pyprof/parse/kernel.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
      "    copying apex/pyprof/parse/db.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
      "    copying apex/pyprof/parse/parse.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
      "    creating build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "    copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "    copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "    copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "    copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "    creating build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
      "    copying apex/contrib/xentropy/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
      "    copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
      "    creating build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
      "    copying apex/contrib/groupbn/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
      "    copying apex/contrib/groupbn/batch_norm.py -> build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
      "    running build_ext\n",
      "    building 'apex_C' extension\n",
      "    creating build/temp.linux-x86_64-3.6\n",
      "    creating build/temp.linux-x86_64-3.6/csrc\n",
      "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c csrc/flatten_unflatten.cpp -o build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -o build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so\n",
      "    building 'amp_C' extension\n",
      "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/amp_C_frontend.cpp -o build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o -O3 -DVERSION_GE_1_1 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_sgd_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_sgd_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_scale_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_axpby_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_l2norm_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_1.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_2.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_adam.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adam.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_novograd.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_novograd.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_sgd_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adam.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_novograd.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so\n",
      "    building 'fused_adam_cuda' extension\n",
      "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/fused_adam_cuda.cpp -o build/temp.linux-x86_64-3.6/csrc/fused_adam_cuda.o -O3 -DVERSION_GE_1_1 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_adam_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/fused_adam_cuda_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/fused_adam_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -O3 --use_fast_math -DVERSION_GE_1_1 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_adam_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/fused_adam_cuda.o build/temp.linux-x86_64-3.6/csrc/fused_adam_cuda_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/fused_adam_cuda.cpython-36m-x86_64-linux-gnu.so\n",
      "    building 'syncbn' extension\n",
      "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/syncbn.cpp -o build/temp.linux-x86_64-3.6/csrc/syncbn.o -O3 -DVERSION_GE_1_1 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/welford.cu -o build/temp.linux-x86_64-3.6/csrc/welford.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/syncbn.o build/temp.linux-x86_64-3.6/csrc/welford.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so\n",
      "    building 'fused_layer_norm_cuda' extension\n",
      "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda.cpp -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o -O3 -DVERSION_GE_1_1 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -maxrregcount=50 -O3 --use_fast_math -DVERSION_GE_1_1 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so\n",
      "    running install_lib\n",
      "    copying build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
      "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
      "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
      "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16util.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
      "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/loss_scaler.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm_kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/LARC.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/multiproc.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/distributed.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm_kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/pooling.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/randomSample.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/optim.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/__main__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/conv.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/misc.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/linear.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/blas.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/utility.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/activation.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/data.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/pointwise.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/recurrentCell.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/reduction.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/embedding.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/softmax.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/loss.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/base.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/index_slice_join_mutate.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/convert.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/prof.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/normalization.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/usage.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/output.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/dropout.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/nvtx/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/nvtx/nvmarker.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/__main__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/nvvp.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/db.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
      "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/parse.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
      "    copying build/lib.linux-x86_64-3.6/apex/normalization/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
      "    copying build/lib.linux-x86_64-3.6/apex/normalization/fused_layer_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/wrap.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/functional_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/tensor_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/torch_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/utils.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/compat.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/scaler.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/amp.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/handle.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/frontend.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/_amp_state.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/_process_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/__version__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/opt.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/_initialize.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/rnn_compat.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/optimizers/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fp16_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_sgd.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_novograd.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/xentropy/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/xentropy/softmax_xentropy.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/groupbn/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n",
      "    copying build/lib.linux-x86_64-3.6/apex/contrib/groupbn/batch_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
      "    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
      "    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/multi_tensor_apply.py -> /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
      "    copying build/lib.linux-x86_64-3.6/apex/RNN/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
      "    copying build/lib.linux-x86_64-3.6/apex/RNN/RNNBackend.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
      "    copying build/lib.linux-x86_64-3.6/apex/RNN/models.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
      "    copying build/lib.linux-x86_64-3.6/apex/RNN/cells.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
      "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
      "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/reparameterization.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
      "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/weight_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
      "    copying build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
      "    copying build/lib.linux-x86_64-3.6/fused_adam_cuda.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
      "    copying build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
      "    copying build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/fp16util.py to fp16util.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/loss_scaler.py to loss_scaler.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/optimized_sync_batchnorm.py to optimized_sync_batchnorm.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/sync_batchnorm_kernel.py to sync_batchnorm_kernel.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/LARC.py to LARC.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/multiproc.py to multiproc.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/distributed.py to distributed.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/sync_batchnorm.py to sync_batchnorm.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/optimized_sync_batchnorm_kernel.py to optimized_sync_batchnorm_kernel.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/pooling.py to pooling.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/randomSample.py to randomSample.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/optim.py to optim.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/__main__.py to __main__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/conv.py to conv.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/misc.py to misc.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/linear.py to linear.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/blas.py to blas.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/utility.py to utility.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/activation.py to activation.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/data.py to data.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/pointwise.py to pointwise.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/recurrentCell.py to recurrentCell.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/reduction.py to reduction.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/embedding.py to embedding.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/softmax.py to softmax.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/loss.py to loss.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/base.py to base.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/index_slice_join_mutate.py to index_slice_join_mutate.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/convert.py to convert.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/prof.py to prof.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/normalization.py to normalization.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/usage.py to usage.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/output.py to output.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/dropout.py to dropout.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx/nvmarker.py to nvmarker.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/__main__.py to __main__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/nvvp.py to nvvp.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/kernel.py to kernel.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/db.py to db.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/parse.py to parse.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/normalization/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/normalization/fused_layer_norm.py to fused_layer_norm.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/wrap.py to wrap.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/functional_overrides.py to functional_overrides.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/tensor_overrides.py to tensor_overrides.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/torch_overrides.py to torch_overrides.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/utils.py to utils.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/compat.py to compat.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/scaler.py to scaler.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/amp.py to amp.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/handle.py to handle.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/frontend.py to frontend.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_amp_state.py to _amp_state.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_process_optimizer.py to _process_optimizer.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/__version__.py to __version__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/opt.py to opt.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_initialize.py to _initialize.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/rnn_compat.py to rnn_compat.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_sgd.py to fused_sgd.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_lamb.py to fused_lamb.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_novograd.py to fused_novograd.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy/softmax_xentropy.py to softmax_xentropy.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn/batch_norm.py to batch_norm.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply/multi_tensor_apply.py to multi_tensor_apply.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/RNNBackend.py to RNNBackend.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/models.py to models.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/cells.py to cells.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/reparameterization.py to reparameterization.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/weight_norm.py to weight_norm.cpython-36.pyc\n",
      "    running install_egg_info\n",
      "    running egg_info\n",
      "    creating apex.egg-info\n",
      "    writing apex.egg-info/PKG-INFO\n",
      "    writing dependency_links to apex.egg-info/dependency_links.txt\n",
      "    writing top-level names to apex.egg-info/top_level.txt\n",
      "    writing manifest file 'apex.egg-info/SOURCES.txt'\n",
      "    writing manifest file 'apex.egg-info/SOURCES.txt'\n",
      "    Copying apex.egg-info to /usr/local/lib/python3.6/dist-packages/apex-0.1-py3.6.egg-info\n",
      "    running install_scripts\n",
      "    writing list of installed files to '/tmp/pip-record-293ocy02/install-record.txt'\n",
      "  Running setup.py install for apex ... \u001b[?25l\u001b[?25hdone\n",
      "  Removing source in /tmp/pip-req-build-c9h2m6um\n",
      "Successfully installed apex-0.1\n",
      "Cleaning up...\n",
      "Removed build tracker '/tmp/pip-req-tracker-pjs4rw11'\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/NVIDIA/apex\n",
    "!pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gnxZ0EVAhR1T"
   },
   "outputs": [],
   "source": [
    "!rm -r apex/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {},
    "colab_type": "code",
    "id": "_HsiH5llhR1W"
   },
   "outputs": [],
   "source": [
    "from auto_augment import AutoAugment, Cutout\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from apex import amp\n",
    "import time\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from albumentations import Compose, RandomBrightnessContrast, ShiftScaleRotate,augmentations\n",
    "from albumentations.pytorch import ToTensor\n",
    "import albumentations as A\n",
    "import random\n",
    "from PIL import Image, ImageFile\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "#package_dir = \"../input/pretrained-models/pretrained-models/pretrained-models.pytorch-master/\"\n",
    "#sys.path.insert(0, package_dir)\n",
    "#import pretrainedmodels\n",
    "device = torch.device(\"cuda:0\")\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pGtv8BL2hR1Z"
   },
   "outputs": [],
   "source": [
    "def seed_everything(SEED):\n",
    "    random.seed(SEED)\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lN-qca90hR1b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import scipy as sp\n",
    "from functools import partial\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "import json\n",
    "class OptimizedRounder(object):\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _kappa_loss(self, coef, X, y):\n",
    "        X_p = np.copy(X)\n",
    "        for i, pred in enumerate(X_p):\n",
    "            if pred < coef[0]:\n",
    "                X_p[i] = 0\n",
    "            elif pred >= coef[0] and pred < coef[1]:\n",
    "                X_p[i] = 1\n",
    "            elif pred >= coef[1] and pred < coef[2]:\n",
    "                X_p[i] = 2\n",
    "            elif pred >= coef[2] and pred < coef[3]:\n",
    "                X_p[i] = 3\n",
    "            else:\n",
    "                X_p[i] = 4\n",
    "\n",
    "        ll = metrics.cohen_kappa_score(y, X_p, weights='quadratic')\n",
    "        return -ll\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        loss_partial = partial(self._kappa_loss, X=X, y=y)\n",
    "        initial_coef = [0.5, 1.5, 2.5, 3.5]\n",
    "        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n",
    "\n",
    "    def predict(self, X, coef):\n",
    "        X_p = np.copy(X)\n",
    "        for i, pred in enumerate(X_p):\n",
    "            if pred < coef[0]:\n",
    "                X_p[i] = 0\n",
    "            elif pred >= coef[0] and pred < coef[1]:\n",
    "                X_p[i] = 1\n",
    "            elif pred >= coef[1] and pred < coef[2]:\n",
    "                X_p[i] = 2\n",
    "            elif pred >= coef[2] and pred < coef[3]:\n",
    "                X_p[i] = 3\n",
    "            else:\n",
    "                X_p[i] = 4\n",
    "        return X_p\n",
    "\n",
    "    def coefficients(self):\n",
    "        return self.coef_['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8-_dGiKOhR1g"
   },
   "outputs": [],
   "source": [
    "def crop_image_from_gray(img, tol=7):\n",
    "    \"\"\"\n",
    "    Crop out black borders\n",
    "    https://www.kaggle.com/ratthachat/aptos-updated-preprocessing-ben-s-cropping\n",
    "    \n",
    "    NOTE: This was used to generate the pre-processed dataset\n",
    "    \"\"\"\n",
    "\n",
    "    if img.ndim == 2:\n",
    "        mask = img > tol\n",
    "        return img[np.ix_(mask.any(1), mask.any(0))]\n",
    "    elif img.ndim == 3:\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        mask = gray_img > tol\n",
    "        check_shape = img[:, :, 0][np.ix_(mask.any(1), mask.any(0))].shape[0]\n",
    "        if (check_shape == 0):\n",
    "            return img\n",
    "        else:\n",
    "            img1 = img[:, :, 0][np.ix_(mask.any(1), mask.any(0))]\n",
    "            img2 = img[:, :, 1][np.ix_(mask.any(1), mask.any(0))]\n",
    "            img3 = img[:, :, 2][np.ix_(mask.any(1), mask.any(0))]\n",
    "            img = np.stack([img1, img2, img3], axis=-1)\n",
    "        return img\n",
    "\n",
    "\n",
    "def circle_crop(img):\n",
    "    \"\"\"\n",
    "    Create circular crop around image centre\n",
    "    \n",
    "    NOTE: This was used to generate the pre-processed dataset\n",
    "    \"\"\"\n",
    "\n",
    "    #img = crop_image_from_gray(img)\n",
    "\n",
    "    height, width, depth = img.shape\n",
    "    largest_side = np.max((height, width))\n",
    "    img = cv2.resize(img, (largest_side, largest_side))\n",
    "\n",
    "    height, width, depth = img.shape\n",
    "\n",
    "    x = int(width / 2)\n",
    "    y = int(height / 2)\n",
    "    r = np.amin((x, y))\n",
    "\n",
    "    circle_img = np.zeros((height, width), np.uint8)\n",
    "    cv2.circle(circle_img, (x, y), int(r), 1, thickness=-1)\n",
    "    img = cv2.bitwise_and(img, img, mask=circle_img)\n",
    "    img = crop_image_from_gray(img)\n",
    "\n",
    "    return img\n",
    "\n",
    "def make_square(img, fill_color=(0, 0, 0, 0)):              #def make_square(im, fill_color=(0, 0, 0, 0)):\n",
    "    if img.shape[0] != img.shape[1]:\n",
    "        s = max(img.shape[0:2])\n",
    "        #Creating a dark square with NUMPY  \n",
    "        f = np.zeros((s,s,3),np.uint8)\n",
    "\n",
    "        #Getting the centering position\n",
    "        ax,ay = (s - img.shape[1])//2,(s - img.shape[0])//2\n",
    "\n",
    "        #Pasting the 'image' in a centering position\n",
    "        f[ay:img.shape[0]+ay,ax:ax+img.shape[1]] = img\n",
    "        return f\n",
    "    else:\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gWpm72jJhR1j"
   },
   "source": [
    "# Optimizer define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ka1eRTP7hR1k"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch.optim.optimizer import Optimizer, required\n",
    "\n",
    "class RAdam(Optimizer):\n",
    "\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
    "        self.buffer = [[None, None, None] for ind in range(10)]\n",
    "        super(RAdam, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(RAdam, self).__setstate__(state)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data.float()\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('RAdam does not support sparse gradients')\n",
    "\n",
    "                p_data_fp32 = p.data.float()\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
    "                else:\n",
    "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
    "\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
    "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
    "\n",
    "                state['step'] += 1\n",
    "                buffered = self.buffer[int(state['step'] % 10)]\n",
    "                if state['step'] == buffered[0]:\n",
    "                    N_sma, step_size = buffered[1], buffered[2]\n",
    "                else:\n",
    "                    buffered[0] = state['step']\n",
    "                    beta2_t = beta2 ** state['step']\n",
    "                    N_sma_max = 2 / (1 - beta2) - 1\n",
    "                    N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
    "                    buffered[1] = N_sma\n",
    "\n",
    "                    # more conservative since it's an approximated value\n",
    "                    if N_sma >= 5:\n",
    "                        step_size = group['lr'] * math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
    "                    else:\n",
    "                        step_size = group['lr'] / (1 - beta1 ** state['step'])\n",
    "                    buffered[2] = step_size\n",
    "\n",
    "                if group['weight_decay'] != 0:\n",
    "                    p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
    "\n",
    "                # more conservative since it's an approximated value\n",
    "                if N_sma >= 5:            \n",
    "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
    "                    p_data_fp32.addcdiv_(-step_size, exp_avg, denom)\n",
    "                else:\n",
    "                    p_data_fp32.add_(-step_size, exp_avg)\n",
    "\n",
    "                p.data.copy_(p_data_fp32)\n",
    "\n",
    "        return loss\n",
    "\n",
    "class PlainRAdam(Optimizer):\n",
    "\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
    "\n",
    "        super(PlainRAdam, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(PlainRAdam, self).__setstate__(state)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data.float()\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('RAdam does not support sparse gradients')\n",
    "\n",
    "                p_data_fp32 = p.data.float()\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
    "                else:\n",
    "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
    "\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
    "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
    "\n",
    "                state['step'] += 1\n",
    "                beta2_t = beta2 ** state['step']\n",
    "                N_sma_max = 2 / (1 - beta2) - 1\n",
    "                N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
    "\n",
    "                if group['weight_decay'] != 0:\n",
    "                    p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
    "\n",
    "                # more conservative since it's an approximated value\n",
    "                if N_sma >= 5:                    \n",
    "                    step_size = group['lr'] * math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
    "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
    "                    p_data_fp32.addcdiv_(-step_size, exp_avg, denom)\n",
    "                else:\n",
    "                    step_size = group['lr'] / (1 - beta1 ** state['step'])\n",
    "                    p_data_fp32.add_(-step_size, exp_avg)\n",
    "\n",
    "                p.data.copy_(p_data_fp32)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "class AdamW(Optimizer):\n",
    "\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0, warmup = 0):\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps,\n",
    "                        weight_decay=weight_decay, warmup = warmup)\n",
    "        super(AdamW, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(AdamW, self).__setstate__(state)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data.float()\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('Adam does not support sparse gradients, please consider SparseAdam instead')\n",
    "\n",
    "                p_data_fp32 = p.data.float()\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
    "                else:\n",
    "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
    "\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                state['step'] += 1\n",
    "\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
    "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
    "\n",
    "                denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
    "                bias_correction1 = 1 - beta1 ** state['step']\n",
    "                bias_correction2 = 1 - beta2 ** state['step']\n",
    "                \n",
    "                if group['warmup'] > state['step']:\n",
    "                    scheduled_lr = 1e-8 + state['step'] * group['lr'] / group['warmup']\n",
    "                else:\n",
    "                    scheduled_lr = group['lr']\n",
    "\n",
    "                step_size = group['lr'] * math.sqrt(bias_correction2) / bias_correction1\n",
    "                \n",
    "                if group['weight_decay'] != 0:\n",
    "                    p_data_fp32.add_(-group['weight_decay'] * scheduled_lr, p_data_fp32)\n",
    "\n",
    "                p_data_fp32.addcdiv_(-step_size, exp_avg, denom)\n",
    "\n",
    "                p.data.copy_(p_data_fp32)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FGshxvc7hR1n"
   },
   "source": [
    "# Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K3Lndlj4hR1o"
   },
   "outputs": [],
   "source": [
    "class RetinopathyDatasetTrain3(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file,transform):\n",
    "        self.transform = transform\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #img_name = os.path.join('../input/resized-2015-2019-blindness-detection-images/resized train 19', self.data.loc[idx, 'id_code'] + '.jpg')\n",
    "        #img_name = os.path.join('../input/cv42croppadcenter260/train/kaggle/working/', self.data.loc[idx, 'id_code'] + '.jpeg')\n",
    "        img_name = os.path.join('kaggle/traindataset19', self.data.loc[idx, 'id_code'] + '.png')\n",
    "        #image = Image.open(img_name)\n",
    "        image = cv2.imread(img_name)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = crop_image_from_gray(image)\n",
    "        image = make_square(image)\n",
    "        #image = image[:,:,::-1]\n",
    "        #image = circle_crop(image)\n",
    "        image = Image.fromarray(image)\n",
    "        label = torch.tensor(self.data.loc[idx, 'diagnosis'])\n",
    "        image = self.transform(image)\n",
    "        if label == torch.tensor(0):\n",
    "            weight = weight0\n",
    "            label = torch.tensor([self.data.loc[idx, 'diagnosis'],0,0,0,0])\n",
    "        elif label == torch.tensor(1):\n",
    "            weight = weight1\n",
    "            label = torch.tensor([self.data.loc[idx, 'diagnosis'],1,0,0,0])\n",
    "        elif label == torch.tensor(2):\n",
    "            weight = weight2\n",
    "            label = torch.tensor([self.data.loc[idx, 'diagnosis'],1,1,0,0])\n",
    "        elif label == torch.tensor(3):\n",
    "            weight = weight3\n",
    "            label = torch.tensor([self.data.loc[idx, 'diagnosis'],1,1,1,0])\n",
    "        else:\n",
    "            weight = weight4\n",
    "            label = torch.tensor([self.data.loc[idx, 'diagnosis'],1,1,1,1])\n",
    "        return {'image': image,#transforms.ToTensor()(image),#image,\n",
    "                'labels': label,\n",
    "                'weight': weight\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7TtXnPGWhR1r"
   },
   "outputs": [],
   "source": [
    "class RetinopathyDatasetValid3(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file,transform):\n",
    "        self.transform = transform\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #img_name = os.path.join('../input/resized-2015-2019-blindness-detection-images/resized train 19', self.data.loc[idx, 'id_code'] + '.jpg')\n",
    "        #img_name = os.path.join('../input/cv42croppadcenter260/valid/kaggle/working/', self.data.loc[idx, 'id_code'] + '.jpeg')\n",
    "        img_name = os.path.join('kaggle/traindataset19', self.data.loc[idx, 'id_code'] + '.png')\n",
    "        #image = Image.open(img_name)\n",
    "        image = cv2.imread(img_name)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = crop_image_from_gray(image)\n",
    "        image = make_square(image)\n",
    "        #image = image[:,:,::-1]\n",
    "        #image = circle_crop(image)\n",
    "        image = Image.fromarray(image)\n",
    "        label = torch.tensor(self.data.loc[idx, 'diagnosis'])\n",
    "        image = self.transform(image)\n",
    "        if label == torch.tensor(0):\n",
    "            weight = weight0\n",
    "            label = torch.tensor([self.data.loc[idx, 'diagnosis'],0,0,0,0])\n",
    "        elif label == torch.tensor(1):\n",
    "            weight = weight1\n",
    "            label = torch.tensor([self.data.loc[idx, 'diagnosis'],1,0,0,0])\n",
    "        elif label == torch.tensor(2):\n",
    "            weight = weight2\n",
    "            label = torch.tensor([self.data.loc[idx, 'diagnosis'],1,1,0,0])\n",
    "        elif label == torch.tensor(3):\n",
    "            weight = weight3\n",
    "            label = torch.tensor([self.data.loc[idx, 'diagnosis'],1,1,1,0])\n",
    "        else:\n",
    "            weight = weight4\n",
    "            label = torch.tensor([self.data.loc[idx, 'diagnosis'],1,1,1,1])\n",
    "        return {'image': image,#transforms.ToTensor()(image),#image,\n",
    "                'labels': label,\n",
    "                'weight': weight\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fy2N9Zg9hR1w"
   },
   "source": [
    "# Get the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "wGxcHyjVhR1x",
    "outputId": "5c8e34e1-f12f-4f1c-9e20-6f1db28d6600"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model.avg_pool = nn.AdaptiveAvgPool2d(1)\\nmodel.last_linear = nn.Sequential(\\n                          nn.BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\\n                          nn.Dropout(p=0.25),\\n                          nn.Linear(in_features=2048, out_features=2048, bias=True),\\n                          nn.ReLU(),\\n                          nn.BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\\n                          nn.Dropout(p=0.5),\\n                          nn.Linear(in_features=2048, out_features=1, bias=True),\\n                         )'"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_raw = EfficientNet.from_name(model_name) \n",
    "#torchvision.models.resnext101_32x8d(pretrained=True)#torchvision.models.resnet101(pretrained=False) #\n",
    "#model.load_state_dict(torch.load(\"../input/pytorch-pretrained-models/resnet101-5d3b4d8f.pth\"))\n",
    "#model.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "#num_features = model.fc.in_features\n",
    "#modules=list(model_raw.children())[:-1]\n",
    "resnext101=model_raw#nn.Sequential(*modules)\n",
    "#for p in model_raw.parameters():\n",
    "#    p.requires_grad = False\n",
    "\n",
    "#model.fc = nn.Linear(2048, 1)\n",
    "#model = pretrainedmodels.__dict__['resnet101'](pretrained='imagenet')\n",
    "'''model.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "model.last_linear = nn.Sequential(\n",
    "                          nn.BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "                          nn.Dropout(p=0.25),\n",
    "                          nn.Linear(in_features=2048, out_features=2048, bias=True),\n",
    "                          nn.ReLU(),\n",
    "                          nn.BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "                          nn.Dropout(p=0.5),\n",
    "                          nn.Linear(in_features=2048, out_features=1, bias=True),\n",
    "                         )'''\n",
    "#num_features = model.fc.in_features\n",
    "#model.fc = nn.Linear(2048, 1)\n",
    "#model.load_state_dict(torch.load(\"../input/pytorch-pretrained-models/resnet101-5d3b4d8f.pth\"))\n",
    "#model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WHPnXJgJhR1z"
   },
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self,resnext101):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.model = resnext101\n",
    "        self.avg_layer = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "        self.max_layer = nn.AdaptiveMaxPool2d(output_size=(1, 1))\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.linear = nn.Linear(output_unit*2, 1+4)#2048#2560\n",
    "        #self.linear2 = nn.Linear(2048, 1+4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        model_out = self.model.extract_features(x)#self.model(x)\n",
    "        avg_pool = torch.squeeze(self.avg_layer(model_out))\n",
    "        max_pool = torch.squeeze(self.max_layer(model_out))\n",
    "        total_pool = torch.cat([avg_pool,max_pool],dim=-1)\n",
    "        dropout_out = self.dropout(total_pool)\n",
    "        logits = self.linear(dropout_out)\n",
    "        #out = torch.sigmoid(logits)\n",
    "        #output = self.linear2(F.relu(logits)+logits)\n",
    "        #logits = self.linear(torch.cat([avg_pool,max_pool]))\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HI2aXpqdhR12"
   },
   "outputs": [],
   "source": [
    "model = NeuralNet(resnext101)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_BmYNLHHhR15"
   },
   "outputs": [],
   "source": [
    "#!pip install torchsummary\n",
    "#from torchsummary import summary\n",
    "#model_raw = model_raw.to(device)\n",
    "#model_raw(torch.cuda.HalfTensor(np.random.normal(0,1,(4,3, 256, 256))))\n",
    "#summary(model, (3, 456, 456))\n",
    "#model_raw.extract_features(torch.cuda.HalfTensor(np.random.normal(0,1,(4,3, 256, 256)))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eKQ18m-vhR17"
   },
   "source": [
    "# Create dataset + optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m84y3AHIhR18"
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((picSize, picSize)),\n",
    "    transforms.CenterCrop(picSize-20),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation((0, 360)),\n",
    "    transforms.ColorJitter(contrast=(0.9, 1.1)),\n",
    "    Cutout(),\n",
    "    transforms.RandomPerspective(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((picSize, picSize)),\n",
    "    #transforms.ColorJitter(brightness=20., contrast=(0.9, 1.1),saturation=20.),\n",
    "    #transforms.RandomPerspective(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8l3QZvl-hR1_"
   },
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gHlGvdshhR2A"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "hahjvurJhR2K",
    "outputId": "5c64e170-190f-4ad3-f605-91f9d50343c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2929 733\n",
      "4.0\n",
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "fold 0 Epoch 0/14\n",
      "----------\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "(0,)\n",
      "[0.50666602 1.5247565  2.51316309 3.29306619]\n",
      "(733,) (733,)\n",
      "Training Loss: 18.1579 Valid Loss: 13.3524 opt QW kapa: 0.8984 raw QW kapa: 0.8966\n",
      "fold 0 Epoch 1/14\n",
      "----------\n",
      "(0,)\n",
      "[0.51973575 1.70695535 2.26560295 2.98922271]\n",
      "(733,) (733,)\n",
      "Training Loss: 14.2010 Valid Loss: 12.5162 opt QW kapa: 0.9013 raw QW kapa: 0.8901\n",
      "fold 0 Epoch 2/14\n",
      "----------\n",
      "(0,)\n",
      "[0.50636743 1.56656323 2.49986857 3.48541328]\n",
      "(733,) (733,)\n",
      "Training Loss: 11.4547 Valid Loss: 11.5844 opt QW kapa: 0.9058 raw QW kapa: 0.9041\n",
      "fold 0 Epoch 3/14\n",
      "----------\n",
      "(0,)\n",
      "[0.50842285 1.5979248  2.50146484 3.40856934]\n",
      "(733,) (733,)\n",
      "Training Loss: 11.0143 Valid Loss: 11.0775 opt QW kapa: 0.9105 raw QW kapa: 0.9078\n",
      "fold 0 Epoch 4/14\n",
      "----------\n",
      "(0,)\n",
      "[0.52325897 1.54386749 2.43369293 3.44614563]\n",
      "(733,) (733,)\n",
      "Training Loss: 10.2457 Valid Loss: 10.8425 opt QW kapa: 0.9085 raw QW kapa: 0.9036\n",
      "fold 0 Epoch 5/14\n",
      "----------\n",
      "(0,)\n",
      "[0.50578022 1.57207088 2.46341896 3.48594761]\n",
      "(733,) (733,)\n",
      "Training Loss: 9.8831 Valid Loss: 10.5679 opt QW kapa: 0.9099 raw QW kapa: 0.9080\n",
      "fold 0 Epoch 6/14\n",
      "----------\n",
      "(0,)\n",
      "[0.56637305 1.62676445 2.24614751 2.76331667]\n",
      "(733,) (733,)\n",
      "Training Loss: 10.0056 Valid Loss: 10.4738 opt QW kapa: 0.9154 raw QW kapa: 0.9077\n",
      "fold 0 Epoch 7/14\n",
      "----------\n",
      "(0,)\n",
      "[0.5   1.575 2.5   3.5  ]\n",
      "(733,) (733,)\n",
      "Training Loss: 9.2790 Valid Loss: 10.2955 opt QW kapa: 0.9141 raw QW kapa: 0.9127\n",
      "fold 0 Epoch 8/14\n",
      "----------\n",
      "(0,)\n",
      "[0.50759166 1.58175356 2.42988921 3.44098773]\n",
      "(733,) (733,)\n",
      "Training Loss: 8.8311 Valid Loss: 10.0867 opt QW kapa: 0.9183 raw QW kapa: 0.9128\n",
      "fold 0 Epoch 9/14\n",
      "----------\n",
      "(0,)\n",
      "[0.54091795 1.55708571 2.64381123 3.08818927]\n",
      "(733,) (733,)\n",
      "Training Loss: 8.1489 Valid Loss: 9.8630 opt QW kapa: 0.9192 raw QW kapa: 0.9097\n",
      "fold 0 Epoch 10/14\n",
      "----------\n",
      "(0,)\n",
      "[0.51453081 1.5219636  2.52257343 3.48643872]\n",
      "(733,) (733,)\n",
      "Training Loss: 8.5015 Valid Loss: 9.8413 opt QW kapa: 0.9226 raw QW kapa: 0.9180\n",
      "fold 0 Epoch 11/14\n",
      "----------\n",
      "(0,)\n",
      "[0.50433665 1.58599357 2.65891853 3.11341071]\n",
      "(733,) (733,)\n",
      "Training Loss: 7.5393 Valid Loss: 9.7369 opt QW kapa: 0.9192 raw QW kapa: 0.9055\n",
      "fold 0 Epoch 12/14\n",
      "----------\n",
      "(0,)\n",
      "[0.51799342 1.55944895 2.46804928 3.22641947]\n",
      "(733,) (733,)\n",
      "Training Loss: 7.7885 Valid Loss: 9.8516 opt QW kapa: 0.9208 raw QW kapa: 0.9100\n",
      "fold 0 Epoch 13/14\n",
      "----------\n",
      "(0,)\n",
      "[0.554862   1.50664533 2.4549396  3.26471388]\n",
      "(733,) (733,)\n",
      "Training Loss: 7.3380 Valid Loss: 9.7965 opt QW kapa: 0.9217 raw QW kapa: 0.9151\n",
      "fold 0 Epoch 14/14\n",
      "----------\n",
      "(0,)\n",
      "[0.51184684 1.54272134 2.4548526  3.10562465]\n",
      "(733,) (733,)\n",
      "Training Loss: 7.2655 Valid Loss: 10.0351 opt QW kapa: 0.9153 raw QW kapa: 0.9059\n",
      "Training complete in 131m 39s\n",
      "done\n",
      "2929 733\n",
      "4.0\n",
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "fold 1 Epoch 0/14\n",
      "----------\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "(0,)\n",
      "[0.53174494 1.60105718 2.54743034 2.81110601]\n",
      "(733,) (733,)\n",
      "Training Loss: 18.4679 Valid Loss: 12.3197 opt QW kapa: 0.9086 raw QW kapa: 0.8965\n",
      "fold 1 Epoch 1/14\n",
      "----------\n",
      "(0,)\n",
      "[0.48021109 1.74914429 2.44149021 2.79742665]\n",
      "(733,) (733,)\n",
      "Training Loss: 13.6582 Valid Loss: 11.5506 opt QW kapa: 0.9124 raw QW kapa: 0.8956\n",
      "fold 1 Epoch 2/14\n",
      "----------\n",
      "(0,)\n",
      "[0.50914867 1.58850341 2.64976561 3.10982475]\n",
      "(733,) (733,)\n",
      "Training Loss: 12.2472 Valid Loss: 10.6354 opt QW kapa: 0.9157 raw QW kapa: 0.9021\n",
      "fold 1 Epoch 3/14\n",
      "----------\n",
      "(0,)\n",
      "[0.51203081 1.67228302 2.51493603 3.06633269]\n",
      "(733,) (733,)\n",
      "Training Loss: 11.5066 Valid Loss: 10.3438 opt QW kapa: 0.9218 raw QW kapa: 0.9093\n",
      "fold 1 Epoch 4/14\n",
      "----------\n",
      "(0,)\n",
      "[0.51218538 1.5209178  2.62528086 3.22000961]\n",
      "(733,) (733,)\n",
      "Training Loss: 10.9946 Valid Loss: 10.6011 opt QW kapa: 0.9112 raw QW kapa: 0.9045\n",
      "fold 1 Epoch 5/14\n",
      "----------\n",
      "(0,)\n",
      "[0.56700074 1.63491335 2.45780285 3.03776559]\n",
      "(733,) (733,)\n",
      "Training Loss: 10.3752 Valid Loss: 9.5281 opt QW kapa: 0.9253 raw QW kapa: 0.9132\n",
      "fold 1 Epoch 6/14\n",
      "----------\n",
      "(0,)\n",
      "[0.50099272 1.63518804 2.66261716 3.30087497]\n",
      "(733,) (733,)\n",
      "Training Loss: 9.4679 Valid Loss: 10.0971 opt QW kapa: 0.9197 raw QW kapa: 0.9112\n",
      "fold 1 Epoch 7/14\n",
      "----------\n",
      "(0,)\n",
      "[0.55622217 1.70721716 2.43557675 2.91610123]\n",
      "(733,) (733,)\n",
      "Training Loss: 9.2912 Valid Loss: 9.5255 opt QW kapa: 0.9201 raw QW kapa: 0.9073\n",
      "fold 1 Epoch 8/14\n",
      "----------\n",
      "(0,)\n",
      "[0.48732971 1.61185226 2.71479288 3.03614108]\n",
      "(733,) (733,)\n",
      "Training Loss: 9.4889 Valid Loss: 9.4887 opt QW kapa: 0.9193 raw QW kapa: 0.9126\n",
      "fold 1 Epoch 9/14\n",
      "----------\n",
      "(0,)\n",
      "[0.53237338 1.6439779  2.62385655 3.14146339]\n",
      "(733,) (733,)\n",
      "Training Loss: 8.8885 Valid Loss: 9.4646 opt QW kapa: 0.9242 raw QW kapa: 0.9114\n",
      "fold 1 Epoch 10/14\n",
      "----------\n",
      "(0,)\n",
      "[0.52691922 1.59172563 2.55441407 3.06494295]\n",
      "(733,) (733,)\n",
      "Training Loss: 8.3680 Valid Loss: 9.6304 opt QW kapa: 0.9225 raw QW kapa: 0.9088\n",
      "fold 1 Epoch 11/14\n",
      "----------\n",
      "(0,)\n",
      "[0.51131811 1.53416605 2.52046824 3.33287067]\n",
      "(733,) (733,)\n",
      "Training Loss: 7.7489 Valid Loss: 10.0398 opt QW kapa: 0.9101 raw QW kapa: 0.9041\n",
      "fold 1 Epoch 12/14\n",
      "----------\n",
      "(0,)\n",
      "[0.57366752 1.59844149 2.34054646 2.94349828]\n",
      "(733,) (733,)\n",
      "Training Loss: 7.3944 Valid Loss: 9.3851 opt QW kapa: 0.9214 raw QW kapa: 0.9092\n",
      "fold 1 Epoch 13/14\n",
      "----------\n",
      "(0,)\n",
      "[0.5612912  1.56032885 2.18979488 2.68149515]\n",
      "(733,) (733,)\n",
      "Training Loss: 7.5994 Valid Loss: 10.2376 opt QW kapa: 0.9214 raw QW kapa: 0.9088\n",
      "fold 1 Epoch 14/14\n",
      "----------\n",
      "(0,)\n",
      "[0.50228157 1.56861534 2.47931099 3.24768982]\n",
      "(733,) (733,)\n",
      "Training Loss: 6.9840 Valid Loss: 9.4608 opt QW kapa: 0.9198 raw QW kapa: 0.9124\n",
      "Training complete in 129m 25s\n",
      "done\n",
      "2929 733\n",
      "4.0\n",
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "fold 2 Epoch 0/14\n",
      "----------\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "(0,)\n",
      "[0.53759107 1.61403674 2.44527185 2.78764415]\n",
      "(733,) (733,)\n",
      "Training Loss: 19.2647 Valid Loss: 12.5029 opt QW kapa: 0.9121 raw QW kapa: 0.9027\n",
      "fold 2 Epoch 1/14\n",
      "----------\n",
      "(0,)\n",
      "[0.57462082 1.60826695 2.37861779 2.92970728]\n",
      "(733,) (733,)\n",
      "Training Loss: 13.8602 Valid Loss: 10.9690 opt QW kapa: 0.9211 raw QW kapa: 0.9020\n",
      "fold 2 Epoch 2/14\n",
      "----------\n",
      "(0,)\n",
      "[0.52868207 1.60858369 2.4671573  3.01137498]\n",
      "(733,) (733,)\n",
      "Training Loss: 12.6337 Valid Loss: 9.9568 opt QW kapa: 0.9254 raw QW kapa: 0.9161\n",
      "fold 2 Epoch 3/14\n",
      "----------\n",
      "(0,)\n",
      "[0.53423419 1.64436296 2.45957911 2.91937847]\n",
      "(733,) (733,)\n",
      "Training Loss: 11.4957 Valid Loss: 9.3134 opt QW kapa: 0.9301 raw QW kapa: 0.9180\n",
      "fold 2 Epoch 4/14\n",
      "----------\n",
      "(0,)\n",
      "[0.45882527 1.74939397 2.62046929 3.22973296]\n",
      "(733,) (733,)\n",
      "Training Loss: 10.7907 Valid Loss: 9.6870 opt QW kapa: 0.9300 raw QW kapa: 0.9185\n",
      "fold 2 Epoch 5/14\n",
      "----------\n",
      "(0,)\n",
      "[0.53140366 1.5664183  2.40067765 3.28307516]\n",
      "(733,) (733,)\n",
      "Training Loss: 10.5875 Valid Loss: 8.5988 opt QW kapa: 0.9283 raw QW kapa: 0.9216\n",
      "fold 2 Epoch 6/14\n",
      "----------\n",
      "(0,)\n",
      "[0.5046875 1.5421875 2.484375  3.5328125]\n",
      "(733,) (733,)\n",
      "Training Loss: 9.9536 Valid Loss: 8.4171 opt QW kapa: 0.9283 raw QW kapa: 0.9262\n",
      "fold 2 Epoch 7/14\n",
      "----------\n",
      "(0,)\n",
      "[0.50157268 1.617181   2.31140868 3.34532644]\n",
      "(733,) (733,)\n",
      "Training Loss: 9.4210 Valid Loss: 8.6369 opt QW kapa: 0.9316 raw QW kapa: 0.9226\n",
      "fold 2 Epoch 8/14\n",
      "----------\n",
      "(0,)\n",
      "[0.51060181 1.51305542 2.51379395 3.47680054]\n",
      "(733,) (733,)\n",
      "Training Loss: 9.3770 Valid Loss: 7.9927 opt QW kapa: 0.9310 raw QW kapa: 0.9306\n",
      "fold 2 Epoch 9/14\n",
      "----------\n",
      "(0,)\n",
      "[0.55389938 1.57655411 2.59160995 2.94966431]\n",
      "(733,) (733,)\n",
      "Training Loss: 8.5931 Valid Loss: 8.1685 opt QW kapa: 0.9339 raw QW kapa: 0.9232\n",
      "fold 2 Epoch 10/14\n",
      "----------\n",
      "(0,)\n",
      "[0.52942239 1.61668504 2.20479331 3.48679816]\n",
      "(733,) (733,)\n",
      "Training Loss: 9.1875 Valid Loss: 8.6143 opt QW kapa: 0.9262 raw QW kapa: 0.9166\n",
      "fold 2 Epoch 11/14\n",
      "----------\n",
      "(0,)\n",
      "[0.54103378 1.55392818 2.35411652 3.17237408]\n",
      "(733,) (733,)\n",
      "Training Loss: 8.5869 Valid Loss: 8.0025 opt QW kapa: 0.9367 raw QW kapa: 0.9261\n",
      "fold 2 Epoch 12/14\n",
      "----------\n",
      "(0,)\n",
      "[0.51875 1.55625 2.4375  3.36875]\n",
      "(733,) (733,)\n",
      "Training Loss: 7.7744 Valid Loss: 7.3075 opt QW kapa: 0.9378 raw QW kapa: 0.9349\n",
      "fold 2 Epoch 13/14\n",
      "----------\n",
      "(0,)\n",
      "[0.52383739 1.6227587  2.4151633  3.13806691]\n",
      "(733,) (733,)\n",
      "Training Loss: 7.5464 Valid Loss: 7.7365 opt QW kapa: 0.9396 raw QW kapa: 0.9298\n",
      "fold 2 Epoch 14/14\n",
      "----------\n",
      "(0,)\n",
      "[0.54230674 1.44883835 2.42221078 2.72744837]\n",
      "(733,) (733,)\n",
      "Training Loss: 7.3177 Valid Loss: 9.0079 opt QW kapa: 0.9291 raw QW kapa: 0.9175\n",
      "Training complete in 129m 24s\n",
      "done\n",
      "2929 733\n",
      "4.0\n",
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "fold 3 Epoch 0/14\n",
      "----------\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "(0,)\n",
      "[0.5   1.575 2.5   3.5  ]\n",
      "(733,) (733,)\n",
      "Training Loss: 18.1396 Valid Loss: 12.1450 opt QW kapa: 0.9114 raw QW kapa: 0.9106\n",
      "fold 3 Epoch 1/14\n",
      "----------\n",
      "(0,)\n",
      "[0.51625718 1.59076908 2.48041952 3.28530379]\n",
      "(733,) (733,)\n",
      "Training Loss: 13.8763 Valid Loss: 10.7912 opt QW kapa: 0.9144 raw QW kapa: 0.9112\n",
      "fold 3 Epoch 2/14\n",
      "----------\n",
      "(0,)\n",
      "[0.52871094 1.64003906 2.65527344 2.8765625 ]\n",
      "(733,) (733,)\n",
      "Training Loss: 12.1729 Valid Loss: 9.9480 opt QW kapa: 0.9208 raw QW kapa: 0.9125\n",
      "fold 3 Epoch 3/14\n",
      "----------\n",
      "(0,)\n",
      "[0.50606989 1.579744   2.46849329 3.09095421]\n",
      "(733,) (733,)\n",
      "Training Loss: 11.7397 Valid Loss: 9.5980 opt QW kapa: 0.9224 raw QW kapa: 0.9155\n",
      "fold 3 Epoch 4/14\n",
      "----------\n",
      "(0,)\n",
      "[0.52709279 1.64750237 2.55559393 3.00070464]\n",
      "(733,) (733,)\n",
      "Training Loss: 10.8046 Valid Loss: 9.7495 opt QW kapa: 0.9232 raw QW kapa: 0.9155\n",
      "fold 3 Epoch 5/14\n",
      "----------\n",
      "(0,)\n",
      "[0.53454039 1.57387059 2.41317509 3.11489736]\n",
      "(733,) (733,)\n",
      "Training Loss: 9.7566 Valid Loss: 9.7291 opt QW kapa: 0.9226 raw QW kapa: 0.9134\n",
      "fold 3 Epoch 6/14\n",
      "----------\n",
      "(0,)\n",
      "[0.51180248 1.55893192 2.40017509 3.34746914]\n",
      "(733,) (733,)\n",
      "Training Loss: 9.8264 Valid Loss: 9.1668 opt QW kapa: 0.9252 raw QW kapa: 0.9204\n",
      "fold 3 Epoch 7/14\n",
      "----------\n",
      "(0,)\n",
      "[0.48743186 1.60396886 2.48630047 3.34605889]\n",
      "(733,) (733,)\n",
      "Training Loss: 9.4860 Valid Loss: 9.7214 opt QW kapa: 0.9227 raw QW kapa: 0.9185\n",
      "fold 3 Epoch 8/14\n",
      "----------\n",
      "(0,)\n",
      "[0.53740234 1.59814453 2.41943359 2.92578125]\n",
      "(733,) (733,)\n",
      "Training Loss: 9.1364 Valid Loss: 9.2611 opt QW kapa: 0.9251 raw QW kapa: 0.9144\n",
      "fold 3 Epoch 9/14\n",
      "----------\n",
      "(0,)\n",
      "[0.54263154 1.53986366 2.60704653 3.11737893]\n",
      "(733,) (733,)\n",
      "Training Loss: 8.7110 Valid Loss: 8.8860 opt QW kapa: 0.9254 raw QW kapa: 0.9161\n",
      "fold 3 Epoch 10/14\n",
      "----------\n",
      "(0,)\n",
      "[0.51224172 1.50907943 2.67050113 3.18220135]\n",
      "(733,) (733,)\n",
      "Training Loss: 8.4212 Valid Loss: 8.8224 opt QW kapa: 0.9303 raw QW kapa: 0.9200\n",
      "fold 3 Epoch 11/14\n",
      "----------\n",
      "(0,)\n",
      "[0.47228278 1.64749486 2.7474453  3.39599432]\n",
      "(733,) (733,)\n",
      "Training Loss: 8.1009 Valid Loss: 10.2599 opt QW kapa: 0.9319 raw QW kapa: 0.9206\n",
      "fold 3 Epoch 12/14\n",
      "----------\n",
      "(0,)\n",
      "[0.50498047 1.55244141 2.48242188 3.50751953]\n",
      "(733,) (733,)\n",
      "Training Loss: 8.1960 Valid Loss: 9.0127 opt QW kapa: 0.9170 raw QW kapa: 0.9157\n",
      "fold 3 Epoch 13/14\n",
      "----------\n",
      "(0,)\n",
      "[0.43384563 1.69361366 2.4693     3.16202765]\n",
      "(733,) (733,)\n",
      "Training Loss: 7.2671 Valid Loss: 9.0976 opt QW kapa: 0.9302 raw QW kapa: 0.9219\n",
      "fold 3 Epoch 14/14\n",
      "----------\n",
      "(0,)\n",
      "[0.55613589 1.53472465 2.32419346 3.12225206]\n",
      "(733,) (733,)\n",
      "Training Loss: 7.0169 Valid Loss: 9.7292 opt QW kapa: 0.9245 raw QW kapa: 0.9137\n",
      "Training complete in 129m 33s\n",
      "done\n",
      "2932 730\n",
      "4.0\n",
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "fold 4 Epoch 0/14\n",
      "----------\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "(0,)\n",
      "[0.5213236  1.50153187 2.51966755 3.35832697]\n",
      "(730,) (730,)\n",
      "Training Loss: 20.2489 Valid Loss: 11.4514 opt QW kapa: 0.9154 raw QW kapa: 0.9125\n",
      "fold 4 Epoch 1/14\n",
      "----------\n",
      "(0,)\n",
      "[0.50751587 1.56296128 2.50783899 3.49396488]\n",
      "(730,) (730,)\n",
      "Training Loss: 14.6243 Valid Loss: 11.2067 opt QW kapa: 0.9169 raw QW kapa: 0.9136\n",
      "fold 4 Epoch 2/14\n",
      "----------\n",
      "(0,)\n",
      "[0.50692369 1.66523706 2.61644549 3.11665381]\n",
      "(730,) (730,)\n",
      "Training Loss: 12.2130 Valid Loss: 10.0373 opt QW kapa: 0.9270 raw QW kapa: 0.9137\n",
      "fold 4 Epoch 3/14\n",
      "----------\n",
      "(0,)\n",
      "[0.54263369 1.6477578  2.46074009 3.17246947]\n",
      "(730,) (730,)\n",
      "Training Loss: 11.9485 Valid Loss: 9.3215 opt QW kapa: 0.9293 raw QW kapa: 0.9222\n",
      "fold 4 Epoch 4/14\n",
      "----------\n",
      "(0,)\n",
      "[0.50197754 1.60700684 2.5982666  3.16777344]\n",
      "(730,) (730,)\n",
      "Training Loss: 11.0261 Valid Loss: 9.2239 opt QW kapa: 0.9282 raw QW kapa: 0.9220\n",
      "fold 4 Epoch 5/14\n",
      "----------\n",
      "(0,)\n",
      "[0.52025606 1.47615118 2.43574079 3.49425545]\n",
      "(730,) (730,)\n",
      "Training Loss: 10.3635 Valid Loss: 8.5763 opt QW kapa: 0.9289 raw QW kapa: 0.9230\n",
      "fold 4 Epoch 6/14\n",
      "----------\n",
      "(0,)\n",
      "[0.51230459 1.56240435 2.29381943 3.51931887]\n",
      "(730,) (730,)\n",
      "Training Loss: 10.5576 Valid Loss: 8.8660 opt QW kapa: 0.9280 raw QW kapa: 0.9183\n",
      "fold 4 Epoch 7/14\n",
      "----------\n",
      "(0,)\n",
      "[0.51944674 1.57267413 2.16234793 3.19853351]\n",
      "(730,) (730,)\n",
      "Training Loss: 9.9621 Valid Loss: 9.6224 opt QW kapa: 0.9289 raw QW kapa: 0.9071\n",
      "fold 4 Epoch 8/14\n",
      "----------\n",
      "(0,)\n",
      "[0.52564204 1.56537851 2.57649844 3.22263122]\n",
      "(730,) (730,)\n",
      "Training Loss: 9.4060 Valid Loss: 8.0653 opt QW kapa: 0.9383 raw QW kapa: 0.9313\n",
      "fold 4 Epoch 9/14\n",
      "----------\n",
      "(0,)\n",
      "[0.52071533 1.63831787 2.59204102 2.92518311]\n",
      "(730,) (730,)\n",
      "Training Loss: 9.2269 Valid Loss: 8.2399 opt QW kapa: 0.9348 raw QW kapa: 0.9265\n",
      "fold 4 Epoch 10/14\n",
      "----------\n",
      "(0,)\n",
      "[0.50651258 1.59336072 2.36834822 3.26594743]\n",
      "(730,) (730,)\n",
      "Training Loss: 8.7404 Valid Loss: 8.8668 opt QW kapa: 0.9274 raw QW kapa: 0.9168\n",
      "fold 4 Epoch 11/14\n",
      "----------\n",
      "(0,)\n",
      "[0.51734395 1.6973352  2.50380588 3.39595022]\n",
      "(730,) (730,)\n",
      "Training Loss: 8.7361 Valid Loss: 8.1574 opt QW kapa: 0.9339 raw QW kapa: 0.9276\n",
      "fold 4 Epoch 12/14\n",
      "----------\n",
      "(0,)\n",
      "[0.58476215 1.57311306 2.22715423 2.8375336 ]\n",
      "(730,) (730,)\n",
      "Training Loss: 8.2500 Valid Loss: 8.4982 opt QW kapa: 0.9318 raw QW kapa: 0.9235\n",
      "fold 4 Epoch 13/14\n",
      "----------\n",
      "(0,)\n",
      "[0.58570318 1.51924541 2.18667158 2.977831  ]\n",
      "(730,) (730,)\n",
      "Training Loss: 8.0013 Valid Loss: 8.1331 opt QW kapa: 0.9330 raw QW kapa: 0.9238\n",
      "fold 4 Epoch 14/14\n",
      "----------\n",
      "(0,)\n",
      "[0.50952304 1.50256637 2.31885831 3.70876345]\n",
      "(730,) (730,)\n",
      "Training Loss: 7.5895 Valid Loss: 7.8623 opt QW kapa: 0.9361 raw QW kapa: 0.9317\n",
      "Training complete in 130m 39s\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "for iiii in range(5):\n",
    "    model.load_state_dict(torch.load(saved_pretrain_model))\n",
    "    if iiii==0:\n",
    "        train_dataset3 = RetinopathyDatasetTrain3(csv_file='kaggle/mycv42/cv42trainzero.csv',\n",
    "                                               transform = train_transform)#test_transform\n",
    "        valid_dataset3 = RetinopathyDatasetValid3(csv_file='kaggle/mycv42/cv42validzero.csv',\n",
    "                                               transform = test_transform)\n",
    "    if iiii==1:\n",
    "        train_dataset3 = RetinopathyDatasetTrain3(csv_file='kaggle/mycv42/cv42trainone.csv',\n",
    "                                               transform = train_transform)#test_transform\n",
    "        valid_dataset3 = RetinopathyDatasetValid3(csv_file='kaggle/mycv42/cv42validone.csv',\n",
    "                                               transform = test_transform)\n",
    "    if iiii==2:\n",
    "        train_dataset3 = RetinopathyDatasetTrain3(csv_file='kaggle/mycv42/cv42traintwo.csv',\n",
    "                                               transform = train_transform)#test_transform\n",
    "        valid_dataset3 = RetinopathyDatasetValid3(csv_file='kaggle/mycv42/cv42validtwo.csv',\n",
    "                                               transform = test_transform)\n",
    "    if iiii==3:\n",
    "        train_dataset3 = RetinopathyDatasetTrain3(csv_file='kaggle/mycv42/cv42trainthree.csv',\n",
    "                                               transform = train_transform)#test_transform\n",
    "        valid_dataset3 = RetinopathyDatasetValid3(csv_file='kaggle/mycv42/cv42validthree.csv',\n",
    "                                               transform = test_transform)\n",
    "    if iiii==4:\n",
    "        train_dataset3 = RetinopathyDatasetTrain3(csv_file='kaggle/mycv42/cv42trainfour.csv',\n",
    "                                               transform = train_transform)#test_transform\n",
    "        valid_dataset3 = RetinopathyDatasetValid3(csv_file='kaggle/mycv42/cv42validfour.csv',\n",
    "                                               transform = test_transform)\n",
    "    \n",
    "\n",
    "    train_dataset = train_dataset3#torch.utils.data.ConcatDataset([train_dataset1,train_dataset2,valid_dataset1,valid_dataset2])\n",
    "    valid_dataset = valid_dataset3#torch.utils.data.ConcatDataset([train_dataset3,valid_dataset3])\n",
    "    valid_data_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=bsz, shuffle=False, num_workers=4)\n",
    "    print(len(train_dataset),len(valid_dataset))\n",
    "    if train_before == True:\n",
    "        accumulation_steps = int(32/bsz)\n",
    "        print(loss_weights)\n",
    "        '''plist = [\n",
    "                 {'params': model.layer4.parameters(), 'lr': 1e-4, 'weight': 0.001},\n",
    "                 {'params': model.last_linear.parameters(), 'lr': 1e-3}\n",
    "                 ]'''\n",
    "        #optimizer = optim.Adam(model.parameters(),lr=2e-4) #optim.Adam(plist, lr=2.5e-4)\n",
    "        optimizer = RAdam(model.parameters(),lr=lr,weight_decay=weight_decay)#RAdam(model.parameters(),lr=2e-4) #AdamW(model.parameters(),lr=2e-4,warmup = warmup)\n",
    "        model, optimizer = amp.initialize(model, optimizer,opt_level=\"O1\")\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer, int((num_epochs*len(train_dataset))))#+new_num_epochs*2*(len(train_dataset3)+len(valid_dataset3)))/32))#StepLR(optimizer, step_size=10,gamma=0.9999)\n",
    "        #scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[10, 16, 22], gamma=0.1)\n",
    "        #scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_rule)\n",
    "        since = time.time()\n",
    "        #criterion = nn.MSELoss()\n",
    "        def criterion(weights,outputs,labels):\n",
    "            #loss = torch.mean(loss_weights*weights*nn.MSELoss(reduction='none')(outputs,labels))\n",
    "            #loss = loss_weights*torch.mean(weights*nn.CrossEntropyLoss(reduction='none')(outputs,labels.long()))\n",
    "            #loss = loss_weights*nn.BCEWithLogitsLoss(weight=weights)(outputs,labels)\n",
    "            loss = torch.mean(loss_weights*weights*nn.MSELoss(reduction='none')(outputs[:,0],labels[:,0]))+auxloss*nn.BCEWithLogitsLoss()(outputs[:,1:],labels[:,1:])\n",
    "            return loss\n",
    "            #torch.mean(loss_weights*weights*nn.MSELoss(reduction='none')(outputs,labels))\n",
    "\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            if epoch == n_freeze:                \n",
    "                for param in model.parameters():\n",
    "                    param.requires_grad = True \n",
    "            #if epoch == 9:\n",
    "            #    for g in optimizer.param_groups:\n",
    "            #        g['lr'] = 1e-4\n",
    "            #elif epoch == 15:\n",
    "            #    for g in optimizer.param_groups:\n",
    "            #        g['lr'] = 1e-5   \n",
    "            #elif epoch == 21:\n",
    "            #    for g in optimizer.param_groups:\n",
    "            #        g['lr'] = 1e-6      \n",
    "            data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=bsz, shuffle=True, num_workers=4)\n",
    "            print('fold {} Epoch {}/{}'.format(iiii, epoch, num_epochs - 1))\n",
    "            print('-' * 10)\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            if see_train == True:\n",
    "                tk0 = tqdm(data_loader, total=int(len(data_loader)))#tk0 = tqdm(data_loader, total=int(len(data_loader)))#tk0 = data_loader\n",
    "            else:\n",
    "                tk0 = data_loader\n",
    "            counter = 0\n",
    "            optimizer.zero_grad()\n",
    "            for bi, d in enumerate(tk0):\n",
    "                #if bi>=10:\n",
    "                #    break\n",
    "                inputs = d[\"image\"]\n",
    "                labels = d[\"labels\"].view(-1, 1+4)\n",
    "                weights = d[\"weight\"].view(-1, 1)\n",
    "                #print(weights)\n",
    "                inputs = inputs.to(device, dtype=torch.float)\n",
    "                labels = labels.to(device, dtype=torch.float)\n",
    "                weights = weights.to(device, dtype=torch.float)\n",
    "                #optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(True):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(weights,outputs, labels)\n",
    "                    with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                        scaled_loss.backward()\n",
    "                    if (bi+1) % accumulation_steps == 0:             # Wait for several backward steps\n",
    "                        optimizer.step()                            # Now we can do an optimizer step\n",
    "                        scheduler.step()\n",
    "                        optimizer.zero_grad()\n",
    "                    #optimizer.step()\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                counter += 1\n",
    "                #tk0.set_postfix(loss=(running_loss / (counter * data_loader.batch_size)))\n",
    "            epoch_loss = running_loss / len(data_loader)\n",
    "\n",
    "            ##validation loss\n",
    "            if see_valid == True:\n",
    "                tk0 = tqdm(valid_data_loader, total=int(len(valid_data_loader)))#valid_data_loader\n",
    "            else:\n",
    "                tk0 = valid_data_loader#tqdm(valid_data_loader, total=int(len(valid_data_loader)))#valid_data_loader\n",
    "            model.eval()\n",
    "            valid_preds = np.array([])#np.zeros((len(valid_dataset), 1))\n",
    "            valid_labels = np.array([])#np.zeros((len(valid_dataset), 1))\n",
    "            print(valid_preds.shape)\n",
    "            running_loss = 0.0\n",
    "            for i, x_batch in enumerate(tk0):\n",
    "                inputs = x_batch[\"image\"]\n",
    "                labels = x_batch[\"labels\"].view(-1,1+4)\n",
    "                weights = x_batch[\"weight\"].view(-1, 1)\n",
    "                inputs = inputs.to(device, dtype=torch.float)\n",
    "                labels = labels.to(device, dtype=torch.float)\n",
    "                weights = weights.to(device, dtype=torch.float)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(weights,outputs, labels)\n",
    "                valid_preds = np.concatenate([valid_preds,outputs[:,0].detach().cpu().squeeze().numpy().ravel()])\n",
    "                valid_labels = np.concatenate([valid_labels,labels[:,0].detach().cpu().squeeze().numpy().ravel()])\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "            valid_loss = running_loss / len(valid_data_loader)\n",
    "            valid_preds = np.array(valid_preds/1.).flatten()\n",
    "            valid_labels = np.array(valid_labels/1.).flatten()\n",
    "            optR = OptimizedRounder()\n",
    "            optR.fit(valid_preds, valid_labels)\n",
    "            coef = optR.coefficients()\n",
    "            print(coef)\n",
    "            print(valid_preds.shape,valid_labels.shape)\n",
    "            valid_preds1 = np.zeros_like(valid_preds)\n",
    "            for i, pred in enumerate(valid_preds):\n",
    "                if pred < coef[0]:\n",
    "                    valid_preds1[i] = 0\n",
    "                elif pred >= coef[0] and pred < coef[1]:\n",
    "                    valid_preds1[i] = 1\n",
    "                elif pred >= coef[1] and pred < coef[2]:\n",
    "                    valid_preds1[i] = 2\n",
    "                elif pred >= coef[2] and pred < coef[3]:\n",
    "                    valid_preds1[i] = 3\n",
    "                else:\n",
    "                    valid_preds1[i] = 4\n",
    "            qw_kappa1 = cohen_kappa_score(valid_labels,valid_preds1,weights='quadratic')\n",
    "            # raw kappa\n",
    "            valid_preds2 = valid_preds\n",
    "            coef = [0.5, 1.5, 2.5, 3.5]\n",
    "            valid_preds2 = np.zeros_like(valid_preds)\n",
    "            for i, pred in enumerate(valid_preds):\n",
    "                if pred < coef[0]:\n",
    "                    valid_preds2[i] = 0\n",
    "                elif pred >= coef[0] and pred < coef[1]:\n",
    "                    valid_preds2[i] = 1\n",
    "                elif pred >= coef[1] and pred < coef[2]:\n",
    "                    valid_preds2[i] = 2\n",
    "                elif pred >= coef[2] and pred < coef[3]:\n",
    "                    valid_preds2[i] = 3\n",
    "                else:\n",
    "                    valid_preds2[i] = 4\n",
    "            qw_kappa2 = cohen_kappa_score(valid_labels,valid_preds2,weights='quadratic')\n",
    "            if qw_kappa1>0.8:\n",
    "                torch.save(model.state_dict(), \"fold{}_model_ep{}.bin\".format(iiii,epoch))\n",
    "            print('Training Loss: {:.4f}'.format(epoch_loss),'Valid Loss: {:.4f}'.format(valid_loss),'opt QW kapa: {:.4f}'.format(qw_kappa1),\n",
    "                 'raw QW kapa: {:.4f}'.format(qw_kappa2))\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "        print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "colab_type": "code",
    "id": "L2EmFzhphR2R",
    "outputId": "67ad9e37-4b73-440d-8be9-8c8cacda74b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto_augment.py       fold1_model_ep6.bin   fold3_model_ep3.bin\n",
      "fold0_model_ep0.bin   fold1_model_ep7.bin   fold3_model_ep4.bin\n",
      "fold0_model_ep10.bin  fold1_model_ep8.bin   fold3_model_ep5.bin\n",
      "fold0_model_ep11.bin  fold1_model_ep9.bin   fold3_model_ep6.bin\n",
      "fold0_model_ep12.bin  fold2_model_ep0.bin   fold3_model_ep7.bin\n",
      "fold0_model_ep13.bin  fold2_model_ep10.bin  fold3_model_ep8.bin\n",
      "fold0_model_ep14.bin  fold2_model_ep11.bin  fold3_model_ep9.bin\n",
      "fold0_model_ep1.bin   fold2_model_ep12.bin  fold4_model_ep0.bin\n",
      "fold0_model_ep2.bin   fold2_model_ep13.bin  fold4_model_ep10.bin\n",
      "fold0_model_ep3.bin   fold2_model_ep14.bin  fold4_model_ep11.bin\n",
      "fold0_model_ep4.bin   fold2_model_ep1.bin   fold4_model_ep12.bin\n",
      "fold0_model_ep5.bin   fold2_model_ep2.bin   fold4_model_ep13.bin\n",
      "fold0_model_ep6.bin   fold2_model_ep3.bin   fold4_model_ep14.bin\n",
      "fold0_model_ep7.bin   fold2_model_ep4.bin   fold4_model_ep1.bin\n",
      "fold0_model_ep8.bin   fold2_model_ep5.bin   fold4_model_ep2.bin\n",
      "fold0_model_ep9.bin   fold2_model_ep6.bin   fold4_model_ep3.bin\n",
      "fold1_model_ep0.bin   fold2_model_ep7.bin   fold4_model_ep4.bin\n",
      "fold1_model_ep10.bin  fold2_model_ep8.bin   fold4_model_ep5.bin\n",
      "fold1_model_ep11.bin  fold2_model_ep9.bin   fold4_model_ep6.bin\n",
      "fold1_model_ep12.bin  fold3_model_ep0.bin   fold4_model_ep7.bin\n",
      "fold1_model_ep13.bin  fold3_model_ep10.bin  fold4_model_ep8.bin\n",
      "fold1_model_ep14.bin  fold3_model_ep11.bin  fold4_model_ep9.bin\n",
      "fold1_model_ep1.bin   fold3_model_ep12.bin  gdrive\n",
      "fold1_model_ep2.bin   fold3_model_ep13.bin  kaggle\n",
      "fold1_model_ep3.bin   fold3_model_ep14.bin  __pycache__\n",
      "fold1_model_ep4.bin   fold3_model_ep1.bin   sample_data\n",
      "fold1_model_ep5.bin   fold3_model_ep2.bin\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "P60fuDYXhR2T",
    "outputId": "46a1d741-c12f-4346-9646-b159b5d4aeb0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!git clone https://github.com/thatbrguy/Dropbox-Uploader.git\\n#!cd see link https://www.freecodecamp.org/news/how-to-transfer-large-files-to-google-colab-and-remote-jupyter-notebooks-26ca252892fa/ for detail\\n!chmod +x Dropbox-Uploader/dropbox_uploader.sh'"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''!git clone https://github.com/thatbrguy/Dropbox-Uploader.git\n",
    "#!cd see link https://www.freecodecamp.org/news/how-to-transfer-large-files-to-google-colab-and-remote-jupyter-notebooks-26ca252892fa/ for detail\n",
    "!chmod +x Dropbox-Uploader/dropbox_uploader.sh'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "uthwG_kBhR2V",
    "outputId": "7e99d02c-94c5-46e3-b644-39474da31de2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!bash Dropbox-Uploader/dropbox_uploader.sh #no need, just run next cell and go on'"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''!bash Dropbox-Uploader/dropbox_uploader.sh #no need, just run next cell and go on'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "3bkNOl4qhR2X",
    "outputId": "16457571-8497-49ce-acec-11322e81e434"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!echo \"ahRVwuNlwQAAAAAAAAAAQr-R6312ZlGCtBbCzzdpJhQT9vncvE1r3XqudR3XpkJw\" > token.txt'"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''!echo \"ahRVwuNlwQAAAAAAAAAAQr-R6312ZlGCtBbCzzdpJhQT9vncvE1r3XqudR3XpkJw\" > token.txt'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "9BmdVa7QhR2a",
    "outputId": "575e94bb-8c9a-47bc-fab0-6be891266f95"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!bash Dropbox-Uploader/dropbox_uploader.sh'"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''!bash Dropbox-Uploader/dropbox_uploader.sh'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "u_53tfUOhR2e",
    "outputId": "e402f29c-5ccc-469c-db6f-48772fc287a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!bash Dropbox-Uploader/dropbox_uploader.sh upload model_ep15.bin model_ep15.bin'"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''!bash Dropbox-Uploader/dropbox_uploader.sh upload model_ep15.bin model_ep15.bin'''"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "aptos_19fold.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
